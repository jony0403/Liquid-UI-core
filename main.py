import asyncio
import os
import uvicorn
import yaml
import httpx
from collections import OrderedDict
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from bs4 import BeautifulSoup
import google.generativeai as genai
from dotenv import load_dotenv

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ê²½ë¡œ ì•ˆì „í•˜ê²Œ ì°¾ê¸°)
current_dir = os.path.dirname(os.path.abspath(__file__))
env_path = os.path.join(current_dir, ".env")
load_dotenv(env_path)

api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    # í˜¹ì‹œë‚˜ .env ë¡œë“œ ì‹¤íŒ¨ ì‹œ í•˜ë“œì½”ë”©ëœ í‚¤ë¼ë„ ìˆìœ¼ë©´ ì—¬ê¸° ë„£ìœ¼ì„¸ìš”.
    print("âš ï¸ ê²½ê³ : API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# 2. Gemini ì„¤ì •
genai.configure(api_key=api_key)

MODEL_NAME = "gemini-2.5-flash"

# ì•ˆì „ ì¥ì¹˜ í•´ì œ (ë„¤ê°€ ì›í•˜ë˜ ì„¤ì • ì ìš©)
safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

model = genai.GenerativeModel(MODEL_NAME, safety_settings=safety_settings)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 3. í”„ë¡¬í”„íŠ¸ ë¡œë” (YAML)
SYSTEM_PROMPTS = {}

@app.on_event("startup")
def load_prompts():
    global SYSTEM_PROMPTS
    try:
        with open("prompt.yaml", "r", encoding="utf-8") as f:
            SYSTEM_PROMPTS = yaml.safe_load(f)
            print(f"âœ… YAML í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ! ëª©ë¡: {list(SYSTEM_PROMPTS.keys())}")
    except FileNotFoundError:
        print("âŒ prompt.yaml íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©.")
        SYSTEM_PROMPTS = {"default": "ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•´ì¤˜."}

# 4. ìºì‹œ ì €ì¥ì†Œ (ì†ë„ í–¥ìƒ ë° ì¤‘ë³µ ìš”ì²­ ë°©ì§€)
class LocalCache:
    def __init__(self, capacity: int = 50):
        self.cache = OrderedDict()
        self.capacity = capacity
    def get(self, key: str):
        if key not in self.cache: return None
        self.cache.move_to_end(key)
        return self.cache[key]
    def put(self, key: str, value: str):
        if key in self.cache: self.cache.move_to_end(key)
        self.cache[key] = value
        if len(self.cache) > self.capacity: self.cache.popitem(last=False)

summary_cache = LocalCache()

# 5. ë°ì´í„° ìš”ì²­ ëª¨ë¸
class AnalyzeRequest(BaseModel):
    url: str
    text_content: str | None = None
    front_image_url: str | None = None # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë³´ë‚¸ ì´ë¯¸ì§€ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í•¨

def detect_domain_type(url: str) -> str:
    u = url.lower()
    if any(k in u for k in ['shop', 'store', 'coupang', 'product', 'gmarket', '11st']): return "shopping"
    if any(k in u for k in ['velog', 'tistory', 'medium', 'tech', 'github']): return "tech"
    if any(k in u for k in ['news', 'article', 'report', 'press']): return "news"
    return "default"

# 6. í–¥ìƒëœ í¬ë¡¤ëŸ¬ (ì œê³µí•´ì¤€ ì½”ë“œ í†µí•©)
# ì£¼ì˜: ì´ í•¨ìˆ˜ëŠ” text_contentê°€ ì—†ì„ ë•Œë§Œ ì‘ë™í•˜ëŠ” ë¹„ìƒìš©ì…ë‹ˆë‹¤.
async def fetch_page_content(url: str):
    DEFAULT_IMAGE = "https://images.unsplash.com/photo-1504711434969-e33886168f5c?q=80&w=3870&auto=format&fit=crop"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://www.google.com/"
    }
    
    async with httpx.AsyncClient(follow_redirects=True, verify=False) as client:
        try:
            # ì¿ íŒ¡ ê°™ì€ ë³´ì•ˆ ì‚¬ì´íŠ¸ëŠ” ì—¬ê¸°ì„œ ì—ëŸ¬ë‚  í™•ë¥ ì´ ë†’ìŒ (ê·¸ë˜ì„œ ë¹„ìƒìš©ì„)
            response = await client.get(url, headers=headers, timeout=3.0)
            
            if response.encoding is None:
                response.encoding = 'utf-8'
                
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ë¶ˆí•„ìš” íƒœê·¸ ì œê±°
            for tag in soup(["script", "style", "nav", "footer", "header", "iframe", "button"]):
                tag.decompose()
            text = soup.get_text(separator=' ', strip=True)[:6000]
            
            image_url = ""
            
            # [ì œê³µëœ ë¡œì§ ì ìš©] ì´ë¯¸ì§€ ì •ë°€ íƒìƒ‰
            candidates = [
                soup.find("meta", property="og:image"),
                soup.find("meta", attrs={"name": "twitter:image"}) 
            ]
            
            for c in candidates:
                if c and c.get("content"):
                    image_url = c["content"]
                    break
            
            if not image_url:
                selectors = ["#img1", ".end_photo_org img", "figure img", "article img"]
                for sel in selectors:
                    img = soup.select_one(sel)
                    if img and img.get("src"):
                        image_url = img["src"]
                        break
            
            return text, image_url if image_url else DEFAULT_IMAGE
            
        except Exception as e:
            print(f"âŒ ì„œë²„ í¬ë¡¤ë§ ì‹¤íŒ¨ (í”„ë¡ íŠ¸ ë°ì´í„° ì‚¬ìš© ê¶Œì¥): {e}")
            return None, DEFAULT_IMAGE

# 7. ìŠ¤íŠ¸ë¦¬ë° ìƒì„±ê¸°
async def gemini_stream_generator(text, image_url, url_key, mode):
    full_text_log = ""
    
    # 1. ì´ë¯¸ì§€ ì‹ í˜¸ ì „ì†¡
    if image_url:
        msg = f"IMAGE_URL::{image_url}::END\n"
        full_text_log += msg
        yield msg
    
    system_instruction = SYSTEM_PROMPTS.get(mode, SYSTEM_PROMPTS.get("default"))

    final_prompt = f"""
    {system_instruction}

    [ì…ë ¥ ë°ì´í„°]
    {text}
    """

    try:
        response = await model.generate_content_async(final_prompt, stream=True)
        async for chunk in response:
            # [ìˆ˜ì •ëœ ë¶€ë¶„] ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ êº¼ë‚´ê¸°
            try:
                # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´(ì¢…ë£Œ íŒ¨í‚·) ë„˜ê¸´ë‹¤
                if chunk.text:
                    full_text_log += chunk.text
                    yield chunk.text
            except ValueError:
                # finish_reasonì´ ì •ìƒì´ì§€ë§Œ í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ë§ˆì§€ë§‰ ì¡°ê°ì„ ë¬´ì‹œí•¨
                continue
        
        # ì™„ë£Œ í›„ ìºì‹œì— ì €ì¥
        summary_cache.put(url_key, full_text_log)
        
    except Exception as e:
        # í˜¹ì‹œë¼ë„ ì§„ì§œ ì—ëŸ¬ê°€ ë‚˜ë©´ ì—¬ê¸°ì„œ ì¡ìŒ
        print(f"Stream Error: {e}")
        yield f"\n[System] ìš”ì•½ ìƒì„± ì¤‘ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."

# 8. ìµœì¢… API ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze")
async def analyze_url(request: AnalyzeRequest):
    print(f"ğŸš€ ìš”ì²­ ìˆ˜ì‹ : {request.url}")
    
    # 1. ìºì‹œ í™•ì¸
    cached = summary_cache.get(request.url)
    if cached:
        print("âš¡ ìºì‹œ ì ì¤‘! ì €ì¥ëœ ê²°ê³¼ ë°˜í™˜")
        async def send_cached(): yield cached
        return StreamingResponse(send_cached(), media_type="text/event-stream")

    mode = detect_domain_type(request.url)

    # 2. ì´ë¯¸ì§€ & í…ìŠ¤íŠ¸ í™•ë³´ ì „ëµ
    # ì „ëµ: í”„ë¡ íŠ¸ì—”ë“œê°€ ë³´ë‚¸ ë°ì´í„°ê°€ 1ìˆœìœ„ (ì¿ íŒ¡ ë°©ì–´ìš©), ì—†ìœ¼ë©´ ì„œë²„ê°€ í¬ë¡¤ë§(ë¹„ìƒìš©)
    final_image = request.front_image_url
    target_text = request.text_content

    if not target_text or len(target_text) < 50:
        print("ğŸ•µï¸ í…ìŠ¤íŠ¸ ë¶€ì¡±, ì„œë²„ê°€ í¬ë¡¤ë§ ì‹œë„...")
        fetched_text, fetched_image = await fetch_page_content(request.url)
        if fetched_text:
            target_text = fetched_text
            # í”„ë¡ íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ì„ ë•Œë§Œ ì„œë²„ ì´ë¯¸ì§€ ì‚¬ìš©
            if not final_image: 
                final_image = fetched_image
        else:
            # ë‘˜ ë‹¤ ì‹¤íŒ¨í–ˆì„ ê²½ìš°
            target_text = "ë³¸ë¬¸ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    if not final_image:
        final_image = "https://images.unsplash.com/photo-1504711434969-e33886168f5c?q=80&w=3870&auto=format&fit=crop"

    print(f"âœ… ë¶„ì„ ì‹œì‘ (ëª¨ë“œ: {mode}, í…ìŠ¤íŠ¸ê¸¸ì´: {len(target_text)})")

    return StreamingResponse(
        gemini_stream_generator(target_text, final_image, request.url, mode),
        media_type="text/event-stream"
    )

if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)